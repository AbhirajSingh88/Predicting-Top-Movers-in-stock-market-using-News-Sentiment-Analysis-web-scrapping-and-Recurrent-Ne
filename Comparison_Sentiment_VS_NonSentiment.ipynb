{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNgrTbaGTxcN",
    "outputId": "3f423c6d-d8f0-4551-a77f-52be874b858f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (1.1.4)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (4.2.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas-datareader) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->pandas-datareader) (1.18.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
      "Collecting get-all-tickers\n",
      "  Downloading https://files.pythonhosted.org/packages/26/a3/d6469bd207bf73b769b94f6000be4ea83cad26a6a32a5fea726cd2522e7e/get_all_tickers-1.7.tar.gz\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from get-all-tickers) (1.1.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from get-all-tickers) (2.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas->get-all-tickers) (1.18.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->get-all-tickers) (2.10)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->get-all-tickers) (1.15.0)\n",
      "Building wheels for collected packages: get-all-tickers\n",
      "  Building wheel for get-all-tickers (setup.py): started\n",
      "  Building wheel for get-all-tickers (setup.py): finished with status 'done'\n",
      "  Created wheel for get-all-tickers: filename=get_all_tickers-1.7-cp36-none-any.whl size=4242 sha256=9af489b20dccd752bfaa425f8e488e92109e7e4924356ae3b776a9df769a7b80\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/8b/ef/6cd3580f4b479aef881a32bd937c282982e3d186b617a663ac\n",
      "Successfully built get-all-tickers\n",
      "Installing collected packages: get-all-tickers\n",
      "Successfully installed get-all-tickers-1.7\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install pandas-datareader\n",
    "pip install get-all-tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lzktlBaSTq6e"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import History\n",
    "from collections import Iterable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "from pandas import Series, DataFrame\n",
    "from get_all_tickers import get_tickers as gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "dkQ8iFWNTreb",
    "outputId": "df1cd752-a554-43ad-eb3f-e26665d876de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-08-08</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-12</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label\n",
       "Date             \n",
       "2008-08-08      0\n",
       "2008-08-11      1\n",
       "2008-08-12      0\n",
       "2008-08-13      0\n",
       "2008-08-14      1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the labels\n",
    "news_data = pd.read_csv('Combined_News_DJIA.csv', index_col=0)\n",
    "labels = news_data[['Label']]\n",
    "labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8_LcBsl1dw-"
   },
   "source": [
    "# Ticker - NKTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "6tohMi_hUHAl",
    "outputId": "10342b8c-584f-4ae3-bc82-6a563d05edbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-08-08</th>\n",
       "      <td>4.79</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1031200.0</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11</th>\n",
       "      <td>4.93</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.81</td>\n",
       "      <td>704400.0</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-12</th>\n",
       "      <td>4.83</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.81</td>\n",
       "      <td>935600.0</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-13</th>\n",
       "      <td>4.77</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1101000.0</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-14</th>\n",
       "      <td>5.03</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.69</td>\n",
       "      <td>1123400.0</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-27</th>\n",
       "      <td>14.33</td>\n",
       "      <td>13.31</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1160200.0</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-28</th>\n",
       "      <td>13.93</td>\n",
       "      <td>13.54</td>\n",
       "      <td>13.58</td>\n",
       "      <td>1069700.0</td>\n",
       "      <td>13.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-29</th>\n",
       "      <td>14.30</td>\n",
       "      <td>13.59</td>\n",
       "      <td>13.99</td>\n",
       "      <td>752000.0</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>14.23</td>\n",
       "      <td>13.73</td>\n",
       "      <td>13.95</td>\n",
       "      <td>993900.0</td>\n",
       "      <td>14.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>14.43</td>\n",
       "      <td>14.04</td>\n",
       "      <td>14.18</td>\n",
       "      <td>559800.0</td>\n",
       "      <td>14.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             High    Low   Open     Volume  Adj Close\n",
       "Date                                                 \n",
       "2008-08-08   4.79   4.43   4.43  1031200.0       4.79\n",
       "2008-08-11   4.93   4.64   4.81   704400.0       4.83\n",
       "2008-08-12   4.83   4.60   4.81   935600.0       4.67\n",
       "2008-08-13   4.77   4.48   4.66  1101000.0       4.72\n",
       "2008-08-14   5.03   4.68   4.69  1123400.0       5.01\n",
       "...           ...    ...    ...        ...        ...\n",
       "2016-06-27  14.33  13.31  14.23  1160200.0      13.39\n",
       "2016-06-28  13.93  13.54  13.58  1069700.0      13.76\n",
       "2016-06-29  14.30  13.59  13.99   752000.0      13.97\n",
       "2016-06-30  14.23  13.73  13.95   993900.0      14.23\n",
       "2016-07-01  14.43  14.04  14.18   559800.0      14.40\n",
       "\n",
       "[1989 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL\n",
    "list_of_tickers=['NKTR'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "yomltGjEU4Dy",
    "outputId": "edc4b5bb-a65a-428c-909b-ab28dfe01022"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-08-08</th>\n",
       "      <td>0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.43</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1031200.0</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11</th>\n",
       "      <td>1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.81</td>\n",
       "      <td>704400.0</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-12</th>\n",
       "      <td>0</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.81</td>\n",
       "      <td>935600.0</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-13</th>\n",
       "      <td>0</td>\n",
       "      <td>4.77</td>\n",
       "      <td>4.48</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1101000.0</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-14</th>\n",
       "      <td>1</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.69</td>\n",
       "      <td>1123400.0</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-27</th>\n",
       "      <td>0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>13.31</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1160200.0</td>\n",
       "      <td>13.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-28</th>\n",
       "      <td>1</td>\n",
       "      <td>13.93</td>\n",
       "      <td>13.54</td>\n",
       "      <td>13.58</td>\n",
       "      <td>1069700.0</td>\n",
       "      <td>13.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-29</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>13.59</td>\n",
       "      <td>13.99</td>\n",
       "      <td>752000.0</td>\n",
       "      <td>13.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>13.73</td>\n",
       "      <td>13.95</td>\n",
       "      <td>993900.0</td>\n",
       "      <td>14.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>1</td>\n",
       "      <td>14.43</td>\n",
       "      <td>14.04</td>\n",
       "      <td>14.18</td>\n",
       "      <td>559800.0</td>\n",
       "      <td>14.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label   High    Low   Open     Volume  Adj Close\n",
       "Date                                                        \n",
       "2008-08-08      0   4.79   4.43   4.43  1031200.0       4.79\n",
       "2008-08-11      1   4.93   4.64   4.81   704400.0       4.83\n",
       "2008-08-12      0   4.83   4.60   4.81   935600.0       4.67\n",
       "2008-08-13      0   4.77   4.48   4.66  1101000.0       4.72\n",
       "2008-08-14      1   5.03   4.68   4.69  1123400.0       5.01\n",
       "...           ...    ...    ...    ...        ...        ...\n",
       "2016-06-27      0  14.33  13.31  14.23  1160200.0      13.39\n",
       "2016-06-28      1  13.93  13.54  13.58  1069700.0      13.76\n",
       "2016-06-29      1  14.30  13.59  13.99   752000.0      13.97\n",
       "2016-06-30      1  14.23  13.73  13.95   993900.0      14.23\n",
       "2016-07-01      1  14.43  14.04  14.18   559800.0      14.40\n",
       "\n",
       "[1989 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "with_sentiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U--gIc2gpsUp"
   },
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cut3ayEUVJxq"
   },
   "outputs": [],
   "source": [
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "801TfP0kp5IS",
    "outputId": "b5cfcd30-9283-4f2d-c529-7dc9467ab88c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.658294</td>\n",
       "      <td>-1.676088</td>\n",
       "      <td>-1.719641</td>\n",
       "      <td>-0.074268</td>\n",
       "      <td>-1.613051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.617279</td>\n",
       "      <td>-1.612689</td>\n",
       "      <td>-1.606773</td>\n",
       "      <td>-0.443055</td>\n",
       "      <td>-1.601171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.646575</td>\n",
       "      <td>-1.624765</td>\n",
       "      <td>-1.606773</td>\n",
       "      <td>-0.182150</td>\n",
       "      <td>-1.648691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.664153</td>\n",
       "      <td>-1.660993</td>\n",
       "      <td>-1.651326</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>-1.633841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.587983</td>\n",
       "      <td>-1.600613</td>\n",
       "      <td>-1.642415</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>-1.547710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1.136545</td>\n",
       "      <td>1.004774</td>\n",
       "      <td>1.191169</td>\n",
       "      <td>0.071306</td>\n",
       "      <td>0.941174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1.019361</td>\n",
       "      <td>1.074210</td>\n",
       "      <td>0.998106</td>\n",
       "      <td>-0.030821</td>\n",
       "      <td>1.051065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1.127756</td>\n",
       "      <td>1.089305</td>\n",
       "      <td>1.119884</td>\n",
       "      <td>-0.389339</td>\n",
       "      <td>1.113435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1.107249</td>\n",
       "      <td>1.131571</td>\n",
       "      <td>1.108004</td>\n",
       "      <td>-0.116360</td>\n",
       "      <td>1.190656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1.165841</td>\n",
       "      <td>1.225160</td>\n",
       "      <td>1.176319</td>\n",
       "      <td>-0.606233</td>\n",
       "      <td>1.241146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Open      High       Low    Volume  Adj Close\n",
       "0    -1.658294 -1.676088 -1.719641 -0.074268  -1.613051\n",
       "1    -1.617279 -1.612689 -1.606773 -0.443055  -1.601171\n",
       "2    -1.646575 -1.624765 -1.606773 -0.182150  -1.648691\n",
       "3    -1.664153 -1.660993 -1.651326  0.004500  -1.633841\n",
       "4    -1.587983 -1.600613 -1.642415  0.029778  -1.547710\n",
       "...        ...       ...       ...       ...        ...\n",
       "1984  1.136545  1.004774  1.191169  0.071306   0.941174\n",
       "1985  1.019361  1.074210  0.998106 -0.030821   1.051065\n",
       "1986  1.127756  1.089305  1.119884 -0.389339   1.113435\n",
       "1987  1.107249  1.131571  1.108004 -0.116360   1.190656\n",
       "1988  1.165841  1.225160  1.176319 -0.606233   1.241146\n",
       "\n",
       "[1989 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_wo_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MVkauYMpe_w"
   },
   "source": [
    "# Train and Test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ilPaiwr2V7pc"
   },
   "outputs": [],
   "source": [
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SNkG6uz4ZX7t"
   },
   "outputs": [],
   "source": [
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ROS_rhwmZihk"
   },
   "outputs": [],
   "source": [
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8e7Wn7lpkkl"
   },
   "source": [
    "# Creating time lags for time series prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "C7zmuxpQZkYD"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "SUqbhIgCeRbf"
   },
   "outputs": [],
   "source": [
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIkDLQmaoVML"
   },
   "source": [
    "# LSTM model for Evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKivMerAduRH",
    "outputId": "eb6c62b9-fb07-4c7c-b463-bcd9b6b08d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 s, sys: 2.45 s, total: 40.9 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiDFX_oEeP2i",
    "outputId": "d47ecd09-d5d3-4215-9e82-f46b76bf944a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.239185571670532\n",
      "Base MSE for the above model: 0.004376023076474667\n"
     ]
    }
   ],
   "source": [
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDyU6XMzojn0"
   },
   "source": [
    "# LSTM model for Evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DfQ4vC8Qe05j",
    "outputId": "a999b6fd-6572-42d0-9ad7-89cd9584b23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.2 s, sys: 2.65 s, total: 41.9 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZBfN893fHa-",
    "outputId": "8907a917-6393-4e95-a770-d74700ea591c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.05492877960205\n",
      "Base MSE for the above model: 0.0036584073677659035\n"
     ]
    }
   ],
   "source": [
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EOI_V4XfOUM"
   },
   "source": [
    "# Comparison of MSE with Sentiment and without Sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "SQWqw9RlfNWV",
    "outputId": "d94b0e50-75c2-40d9-fbf3-930b7fd86bb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0043                    0.0036"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0043], 'MSE With Sentiment Score': [0.0036]}\n",
    "df_comparison1 = pd.DataFrame(data=d)\n",
    "df_comparison1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgNtRkllum-K"
   },
   "source": [
    "# Ticker - AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "XoZuFe3pqWAz",
    "outputId": "bf7cfedf-363d-48b7-a0a1-05bb40b07fe0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-08-08</th>\n",
       "      <td>5.26</td>\n",
       "      <td>5.05</td>\n",
       "      <td>5.19</td>\n",
       "      <td>22304100</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-11</th>\n",
       "      <td>5.20</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.10</td>\n",
       "      <td>15651300</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-12</th>\n",
       "      <td>5.35</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.20</td>\n",
       "      <td>30836400</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-13</th>\n",
       "      <td>5.23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>19108700</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-14</th>\n",
       "      <td>5.37</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.15</td>\n",
       "      <td>18960500</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-27</th>\n",
       "      <td>5.05</td>\n",
       "      <td>4.65</td>\n",
       "      <td>4.88</td>\n",
       "      <td>31025300</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-28</th>\n",
       "      <td>5.19</td>\n",
       "      <td>4.91</td>\n",
       "      <td>4.95</td>\n",
       "      <td>29221400</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-29</th>\n",
       "      <td>5.40</td>\n",
       "      <td>5.10</td>\n",
       "      <td>5.31</td>\n",
       "      <td>33118300</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>5.19</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.13</td>\n",
       "      <td>26124800</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>5.14</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.09</td>\n",
       "      <td>18255900</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            High   Low  Open    Volume  Adj Close\n",
       "Date                                             \n",
       "2008-08-08  5.26  5.05  5.19  22304100       5.13\n",
       "2008-08-11  5.20  5.03  5.10  15651300       5.11\n",
       "2008-08-12  5.35  5.12  5.20  30836400       5.21\n",
       "2008-08-13  5.23  5.00  5.20  19108700       5.15\n",
       "2008-08-14  5.37  5.14  5.15  18960500       5.30\n",
       "...          ...   ...   ...       ...        ...\n",
       "2016-06-27  5.05  4.65  4.88  31025300       4.72\n",
       "2016-06-28  5.19  4.91  4.95  29221400       5.12\n",
       "2016-06-29  5.40  5.10  5.31  33118300       5.13\n",
       "2016-06-30  5.19  4.95  5.13  26124800       5.14\n",
       "2016-07-01  5.14  5.00  5.09  18255900       5.07\n",
       "\n",
       "[1989 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL\n",
    "list_of_tickers=['AMD'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6u26NEKYu5Q0"
   },
   "outputs": [],
   "source": [
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8eNdLWXvtq3"
   },
   "source": [
    "# LSTM Model for evaluation without the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCAR2CEJvBpk",
    "outputId": "56501dc6-137c-43dc-a265-cc3817cf89af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.534465551376343\n",
      "Base MSE for the above model: 0.002150504384189844\n",
      "CPU times: user 39.9 s, sys: 2.32 s, total: 42.2 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7Pi5vzNwIf3"
   },
   "source": [
    "# LSTM Model for evaluation with the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDKriWNAvh4G",
    "outputId": "116d6246-fe63-4e32-c782-ce61a677a798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.21262001991272\n",
      "Base MSE for the above model: 0.0017484786221757531\n",
      "CPU times: user 39.4 s, sys: 2.3 s, total: 41.7 s\n",
      "Wall time: 27.6 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3j6Qcf17xTiL"
   },
   "source": [
    "# Comparison of MSE with Sentiment and without Sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "KhOH5p-twSKe",
    "outputId": "8241ff11-96e0-4cb7-d23e-5abc1ca1fc9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0021                    0.0017"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0021], 'MSE With Sentiment Score': [0.0017]}\n",
    "df_comparison2 = pd.DataFrame(data=d)\n",
    "df_comparison2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbv-TWlo1iY-"
   },
   "source": [
    "# Ticker - KGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "FdvnBTt41YFB"
   },
   "outputs": [],
   "source": [
    "##ZION,KGC,AMD,SOHU,BLIN,WMT,AMGN,NKTR,T,AAPL\n",
    "list_of_tickers=['KGC'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfHBRp122A5O"
   },
   "source": [
    "# LSTM for Evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebk2NlUS1yAc",
    "outputId": "be69787b-86bd-4d07-a2c3-4f4adaef8879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.80247950553894\n",
      "Base MSE for the above model: 0.004240995738655329\n",
      "CPU times: user 40.1 s, sys: 2.35 s, total: 42.4 s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHkBhlHE2Ky1"
   },
   "source": [
    "# LSTM for Evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJ1JIx_b1zDY",
    "outputId": "d00c0198-c9cb-4b19-ecaf-93e94b086ab1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.028542280197144\n",
      "Base MSE for the above model: 0.00516292080283165\n",
      "CPU times: user 39 s, sys: 2.17 s, total: 41.2 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model.add(keras.layers.Dense(units = 1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "OiFvN45014JH",
    "outputId": "c2976734-315d-4e1f-9dfe-065ff9fe5b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0051                    0.0042"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0051], 'MSE With Sentiment Score': [0.0042]}\n",
    "df_comparison3 = pd.DataFrame(data=d)\n",
    "df_comparison3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJAFP6cA2qx5"
   },
   "source": [
    "# Ticker - Zion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "F8jjyrpi2W8E"
   },
   "outputs": [],
   "source": [
    "##ZION,SOHU,BLIN,WMT,AMGN,T,AAPL\n",
    "list_of_tickers=['ZION'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpsohe7_3EFE"
   },
   "source": [
    "# LSTM for prediction without the sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtpGKMcG23_J",
    "outputId": "b3f4938d-1b7f-4391-c14f-7661777847c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.982330560684204\n",
      "Base MSE for the above model: 0.0012966925278306007\n",
      "CPU times: user 40.2 s, sys: 2.39 s, total: 42.6 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_zion = Sequential()\n",
    "lstm_model_zion.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_zion.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_zion.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_zion.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glJ1AeCV2_Fi"
   },
   "source": [
    "# LSTM using the sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Rlqze-U269s",
    "outputId": "523e3883-c2c6-47aa-ecd1-b936e6bfa568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.19249415397644\n",
      "Base MSE for the above model: 0.0013115211622789502\n",
      "CPU times: user 39.3 s, sys: 2.24 s, total: 41.6 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_zion1 = Sequential()\n",
    "lstm_model_zion1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_zion1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_zion1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_zion1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "DqdjndAE3K2m",
    "outputId": "ef653a4b-2dc2-4974-8790-ad549980ea4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0012                    0.0013"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0012], 'MSE With Sentiment Score': [0.0013]}\n",
    "df_comparison4 = pd.DataFrame(data=d)\n",
    "df_comparison4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fihREBBV3ZJj"
   },
   "source": [
    "# Ticker - AMGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "3j7puc3b3WXF"
   },
   "outputs": [],
   "source": [
    "##SOHU,BLIN,WMT,AMGN,T,AAPL\n",
    "list_of_tickers=['AMGN'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vsu8QBY64ljg"
   },
   "source": [
    "# LSTM evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqWE6eop3hYR",
    "outputId": "65ceeda6-24e7-4b42-a1e1-b3df46b8a301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.57383966445923\n",
      "Base MSE for the above model: 0.0016074971063062549\n",
      "CPU times: user 39.9 s, sys: 2.19 s, total: 42.1 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_amgn = Sequential()\n",
    "lstm_model_amgn.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_amgn.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_amgn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_amgn.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wslQ0gSJ4bZW"
   },
   "source": [
    "# LSTM evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybyi0B0Z3mZk",
    "outputId": "99015513-31c8-477d-c36b-10cf5d098001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.62963342666626\n",
      "Base MSE for the above model: 0.001529995002783835\n",
      "CPU times: user 40 s, sys: 2.35 s, total: 42.4 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model1 = Sequential()\n",
    "lstm_model1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "golJ79e73nbI",
    "outputId": "6ca106bc-011a-4215-c631-334c2e440348"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0016                    0.0015"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0016], 'MSE With Sentiment Score': [0.0015]}\n",
    "df_comparison5 = pd.DataFrame(data=d)\n",
    "df_comparison5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjmPGARp5pS-"
   },
   "source": [
    "# Ticker - SOHU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "oWHVvDg_37FT"
   },
   "outputs": [],
   "source": [
    "##,BLIN,WMT,T,AAPL\n",
    "list_of_tickers=['SOHU'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQ0rl29e6jvu"
   },
   "source": [
    "# LSTM evaluation without using the sentiment scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUjeawb15yZ9",
    "outputId": "7fea7b8e-dfc9-481e-81b7-b4e99b378b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.07793951034546\n",
      "Base MSE for the above model: 0.006253760773688555\n",
      "CPU times: user 40.5 s, sys: 2.48 s, total: 42.9 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_sohu = Sequential()\n",
    "lstm_model_sohu.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_sohu.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_sohu.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_sohu.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQtqaU_h6Y55"
   },
   "source": [
    "# LSTM evaluation using the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eon4Apk65u95",
    "outputId": "68ab20c9-ea63-4750-c2c7-98b8e6dcd953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.23858404159546\n",
      "Base MSE for the above model: 0.006465512793511152\n",
      "CPU times: user 40.5 s, sys: 2.38 s, total: 42.9 s\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_sohu1 = Sequential()\n",
    "lstm_model_sohu1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_sohu1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_sohu1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_sohu1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "qNu2-in-6VF2",
    "outputId": "4c21bd54-1f6a-4212-e7bf-7ef3a60f87e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0062                    0.0064"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0062], 'MSE With Sentiment Score': [0.0064]}\n",
    "df_comparison6 = pd.DataFrame(data=d)\n",
    "df_comparison6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kYteRkoCt8i"
   },
   "source": [
    "# Ticker - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "MWPokIGF6w1T"
   },
   "outputs": [],
   "source": [
    "##,BLIN,WMT,T,AAPL\n",
    "list_of_tickers=['T'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-nJevS3DMgd"
   },
   "source": [
    "# LSTM Evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hNCodBoVCxee",
    "outputId": "880cbf29-09c3-498f-c3c6-525277bb6044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.035260915756226\n",
      "Base MSE for the above model: 0.0915767177939415\n",
      "CPU times: user 40.8 s, sys: 2.2 s, total: 43 s\n",
      "Wall time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_t = Sequential()\n",
    "lstm_model_t.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_t.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_t.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_t.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh-VxeUlDA-_"
   },
   "source": [
    "# LSTM evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vqm4hemRC8ih",
    "outputId": "ddb4367a-7ed5-4bc9-8e05-848b8066c440"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.730696439743042\n",
      "Base MSE for the above model: 0.09170409291982651\n",
      "CPU times: user 40.1 s, sys: 2.31 s, total: 42.4 s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_t1 = Sequential()\n",
    "lstm_model_t1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_t1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_t1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_t1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "T1Yq6YE1DK5u",
    "outputId": "a14d6278-214d-4133-b400-4db21fd57cee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0091                    0.0091"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0091], 'MSE With Sentiment Score': [0.0091]}\n",
    "df_comparison7 = pd.DataFrame(data=d)\n",
    "df_comparison7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdk0T-mODf6O"
   },
   "source": [
    "# Ticker -AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4RhB97GEDY_f"
   },
   "outputs": [],
   "source": [
    "##,BLIN,WMT,AAPL\n",
    "list_of_tickers=['AAPL'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64NGmtLXD7fG"
   },
   "source": [
    "# LSTM evaluation without sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkgKXCONDikz",
    "outputId": "353dab9e-81c3-4f1b-cbfe-05d9ef7c833d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.980021715164185\n",
      "Base MSE for the above model: 0.003923584241420031\n",
      "CPU times: user 40.4 s, sys: 2.33 s, total: 42.8 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_ap = Sequential()\n",
    "lstm_model_ap.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_ap.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_ap.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_ap.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hASN7lGzD2gW"
   },
   "source": [
    "# LSTM evaluation with sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xip4NXeNDq2C",
    "outputId": "f1d5055c-599e-4909-cb50-9e0d375b8063"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.52291989326477\n",
      "Base MSE for the above model: 0.003186717163771391\n",
      "CPU times: user 40.7 s, sys: 2.51 s, total: 43.2 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_ap1 = Sequential()\n",
    "lstm_model_ap1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_ap1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_ap1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_ap1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "UkCGq8W1D05R",
    "outputId": "f149fae3-cdee-4659-8c90-c1b5586bb551"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0039                    0.0031"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0039], 'MSE With Sentiment Score': [0.0031]}\n",
    "df_comparison8 = pd.DataFrame(data=d)\n",
    "df_comparison8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qh6mX5-CEOlY"
   },
   "source": [
    "# Ticker - BLIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "NQmDoMbwEIMw"
   },
   "outputs": [],
   "source": [
    "##BLIN,WMT\n",
    "list_of_tickers=['BLIN'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpkdnTBuEefl"
   },
   "source": [
    "# LSTM evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHJRE42sENQF",
    "outputId": "d3b55299-86b3-42ba-9cfe-f737b968ba31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.43800139427185\n",
      "Base MSE for the above model: 0.007138579618185759\n",
      "CPU times: user 39.6 s, sys: 2.3 s, total: 41.9 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_bl = Sequential()\n",
    "lstm_model_bl.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_bl.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_bl.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_bl.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIFS5JDOEjrU"
   },
   "source": [
    "# LSTM evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mN-0V1sPEXqa",
    "outputId": "85024107-29a8-404a-e869-0bc60bb51d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  27.422298908233643\n",
      "Base MSE for the above model: 0.007361146155744791\n",
      "CPU times: user 39.7 s, sys: 2.23 s, total: 42 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_bl1 = Sequential()\n",
    "lstm_model_bl1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_bl1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_bl1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_bl1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "26_sdBWDEdg-",
    "outputId": "330f8fdd-ff51-4b0c-9547-093c643c1b11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0071                    0.0073"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0071], 'MSE With Sentiment Score': [0.0073]}\n",
    "df_comparison9 = pd.DataFrame(data=d)\n",
    "df_comparison9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_LjENPGFRST"
   },
   "source": [
    "# Ticker - WMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "lDE2BahVFNOD"
   },
   "outputs": [],
   "source": [
    "##WMT\n",
    "list_of_tickers=['WMT'] \n",
    "\n",
    "for i in list_of_tickers:\n",
    "  start = datetime.datetime(2008, 8, 8)\n",
    "  end = datetime.datetime(2016, 7, 1)\n",
    "  zion = web.DataReader(i, 'yahoo', start, end)\n",
    "data=zion.drop(['Close'],axis=1)\n",
    "temp_data=zion.drop(['Close'],axis=1)\n",
    "temp_data\n",
    "\n",
    "with_sentiment_data=pd.merge(labels, temp_data, right_index=True, left_index=True)\n",
    "\n",
    "#Scaling the variables(x) and variable(y)\n",
    "sca = temp_data.iloc[:,:]\n",
    "\n",
    "#Standardization of data is required as the dataset consists of variables of different scales\n",
    "sc = StandardScaler()\n",
    "scaled_wo_sentiment = sc.fit_transform(sca)\n",
    "scaled_wo_sentiment = pd.DataFrame(data=scaled_wo_sentiment,columns=['Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "with_sentiment_data = sc.fit_transform(with_sentiment_data)\n",
    "with_sentiment_data = pd.DataFrame(data=with_sentiment_data,columns=['Label','Open','High','Low','Volume','Adj Close'])\n",
    "\n",
    "x_without_sentiment_scores = scaled_wo_sentiment.iloc[:,0:4]\n",
    "y_without_sentiment_scores = scaled_wo_sentiment.iloc[:,4]\n",
    "\n",
    "x_with_sentiment_scores = with_sentiment_data.iloc[:,0:5]\n",
    "y_with_sentiment_scores = with_sentiment_data.iloc[:,5]\n",
    "#Splitting data into training(70% data) and testing data(30% data)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,random_state=1)\n",
    "\n",
    "x_train_without_sentiment_scores, x_test_without_sentiment_scores, y_train_without_sentiment_scores, y_test_without_sentiment_scores = train_test_split(x_without_sentiment_scores, y_without_sentiment_scores, test_size=0.30,random_state=1)\n",
    "x_train_with_sentiment_scores, x_test_with_sentiment_scores, y_train_with_sentiment_scores, y_test_with_sentiment_scores = train_test_split(x_with_sentiment_scores, y_with_sentiment_scores, test_size=0.30,random_state=1)\n",
    "\n",
    "\n",
    "class fun_t(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "def dataset(xtra,x,y,time_steps):\n",
    "  import numpy as np\n",
    "  xs, ys = [], []\n",
    "  xtra=xtra\n",
    "  xnum=xtra.to_numpy()\n",
    "  for i in range(len(x) - time_steps):\n",
    "    v = x.iloc[i : (i+time_steps)].to_numpy()\n",
    "    comb=np.concatenate((v, xnum[i+time_steps]), axis=None)\n",
    "    xs.append(comb)\n",
    "    ys.append(y.iloc[i+time_steps]) #So that next y is considered\n",
    "  return np.array(xs), np.array(ys)\n",
    "\n",
    "\n",
    "TIME_STEPS = 1\n",
    "\n",
    "#creating lags for with sentiment scores\n",
    "\n",
    "x_train_with_sentiment_scores, y_train_with_sentiment_scores = dataset(x_train_with_sentiment_scores,y_train_with_sentiment_scores, y_train_with_sentiment_scores, TIME_STEPS)\n",
    "x_test_with_sentiment_scores, y_test_with_sentiment_scores = dataset(x_test_with_sentiment_scores,y_test_with_sentiment_scores, y_test_with_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "#creating lags for without sentiment scores\n",
    "\n",
    "x_train_without_sentiment_scores, y_train_without_sentiment_scores = dataset(x_train_without_sentiment_scores,y_train_without_sentiment_scores, y_train_without_sentiment_scores, TIME_STEPS)\n",
    "x_test_without_sentiment_scores, y_test_without_sentiment_scores = dataset(x_test_without_sentiment_scores,y_test_without_sentiment_scores, y_test_without_sentiment_scores, TIME_STEPS)\n",
    "\n",
    "\n",
    "\n",
    "x_train_with_sentiment_scores=x_train_with_sentiment_scores.reshape((x_train_with_sentiment_scores.shape[0], 1,x_train_with_sentiment_scores.shape[1]))\n",
    "x_test_with_sentiment_scores=x_test_with_sentiment_scores.reshape((x_test_with_sentiment_scores.shape[0], 1,x_test_with_sentiment_scores.shape[1]))\n",
    "\n",
    "x_train_without_sentiment_scores=x_train_without_sentiment_scores.reshape((x_train_without_sentiment_scores.shape[0], 1,x_train_without_sentiment_scores.shape[1]))\n",
    "x_test_without_sentiment_scores=x_test_without_sentiment_scores.reshape((x_test_without_sentiment_scores.shape[0], 1,x_test_without_sentiment_scores.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmHFgWomFtZm"
   },
   "source": [
    "# LSTM Evaluation without sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cx_dK6bEFWWf",
    "outputId": "e1de45a9-679f-48c2-e98e-4714333d2960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  28.465714693069458\n",
      "Base MSE for the above model: 0.029594529420137405\n",
      "CPU times: user 40.5 s, sys: 2.34 s, total: 42.8 s\n",
      "Wall time: 28.8 s\n"
     ]
    }
   ],
   "source": [
    "#Evaluation using without sentiment\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_wm = Sequential()\n",
    "lstm_model_wm.add(keras.layers.LSTM(units = 1, input_shape = (x_train_without_sentiment_scores.shape[1],x_train_without_sentiment_scores.shape[2])))\n",
    "lstm_model_wm.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_wm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_wm.fit(x_train_without_sentiment_scores,y_train_without_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIEU1J-rFyVp"
   },
   "source": [
    "# LSTM Evaluation with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-RECE0h6FbkN",
    "outputId": "35ad8c79-db93-4c32-d973-8976340ceb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Short Term Memory Model Time Taken:  26.94499135017395\n",
      "Base MSE for the above model: 0.03206600248813629\n",
      "CPU times: user 38.9 s, sys: 2.24 s, total: 41.2 s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "#now evaluating the performance of the model using the sentiment labels\n",
    "\n",
    "#Evaluation using the Expertise\n",
    "%%time\n",
    "np.random.seed = 1   \n",
    "tf.random.set_seed = 2  \n",
    "time3=fun_t()\n",
    "history=History()\n",
    "lstm_model_wm1 = Sequential()\n",
    "lstm_model_wm1.add(keras.layers.LSTM(units = 1, input_shape = (x_train_with_sentiment_scores.shape[1],x_train_with_sentiment_scores.shape[2])))\n",
    "lstm_model_wm1.add(keras.layers.Dense(units = 1))\n",
    "lstm_model_wm1.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = lstm_model_wm1.fit(x_train_with_sentiment_scores,y_train_with_sentiment_scores, epochs= 150, shuffle = False, batch_size = 7, callbacks=[history,time3],validation_split = 0.3,verbose = 0)\n",
    "\n",
    "time_lstm = list(time3.times)\n",
    "print('Long Short Term Memory Model Time Taken: ',sum(time_lstm))\n",
    "train_lstm = history.history.get('loss')\n",
    "val_lstm = history.history.get('val_loss')\n",
    "\n",
    "base_mse=val_lstm[-1]\n",
    "print('Base MSE for the above model:',base_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "id": "GJx-fmZ7FeD2",
    "outputId": "365f1d01-31ce-4a41-88c5-823766d307a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE Without using Sentiment Score</th>\n",
       "      <th>MSE With Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSE Without using Sentiment Score  MSE With Sentiment Score\n",
       "0                             0.0295                     0.032"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'MSE Without using Sentiment Score': [0.0295], 'MSE With Sentiment Score': [0.032]}\n",
    "df_comparison10 = pd.DataFrame(data=d)\n",
    "df_comparison10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXWjj9OsGeBS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment_v/s_non-sentiment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
